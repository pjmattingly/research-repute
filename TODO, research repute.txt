TODO, reading; AI-generated text is hard to spot. It could play a big role in the 2024 campaign
    this talks about the difficulty of detecting AT generated text

    see:
    https://text.npr.org/1183684732

    and:
    https://news.ycombinator.com/item?id=36522430
done

--

TODO, reading; G.O.P. Targets Researchers Who Study Disinformation Ahead of 2024 Election
    see:
    https://www.nytimes.com/2023/06/19/technology/gop-disinformation-researchers-2024-election.html
done

--

TODO, reading; The Evolution Of Hacker News
    see:
    https://techcrunch.com/2013/05/18/the-evolution-of-hacker-news/

    --

    I've read this before, but it needs to be noted

    I believe that Hacker News is a system in the wild that implements a proto-form of repute-based discussion and trust
    you get points for posting, and making good comments
    there are no downvotes
    those without a lot of points aren't as visisble

    this article talks about Hacker News developed
    it seems like a logical out growth of Reddit and its drawbacks

    and:
    https://en.wikipedia.org/wiki/Hacker_News

    --

    while checking for discussions surround this work, I found this
        see:
        The Evolution of Trust (2017)
        https://ncase.me/trust/

    which is a game, not an article
    but it's described as:

    "A game about the game theory of social trust & cooperation"

    so perhaps there is a game theory application that deals with reputation and trust?

    added to TODO
done

--

TOOD, reading, Hacker News
    see:
    https://en.wikipedia.org/wiki/Hacker_News
done

TODO, Reading, Misinformation is at Most Weakly Related to Lack of Knowledge
    see:
    https://reasonalone.substack.com/p/misinformation-is-at-most-weakly

    --

    interesting, but off topic
done

TODO, reading, How to Prepare for the Deluge of Generative AI on Social Media
    see:
    https://knightcolumbia.org/content/how-to-prepare-for-the-deluge-of-generative-ai-on-social-media

    --

    see:
    https://github.com/pjmattingly/research-repute/tree/main/bib/How%20to%20Prepare%20for%20the%20Deluge%20of%20Generative%20AI%20on%20Social%20Media
done

TODO, reading, "AI can spread misinformation better than humans, study claims"
    see:
    https://www.siliconrepublic.com/machines/ai-misinformation-gpt-3-humans

    --

    the article then points to a study
        see:
        https://www.science.org/doi/10.1126/sciadv.adh1850
    which can be read instead of the article

    but the article also points to several other items
        Google shares tools to spot misleading AI-generated images
        https://www.siliconrepublic.com/machines/google-ai-generated-images-irish-times-hoax

        Government sets up anti-disinformation working group
        https://www.siliconrepublic.com/business/disinformation-working-group-ireland-media-literacy

        The great AI debate: Moratorium or responsible progress?
        https://www.siliconrepublic.com/machines/the-generative-ai-debate-ethical-moratorium-innovation

    adding TODO for these other items

    --

    then creating bib item for study
        AI model GPT-3 (dis)informs us better than humans
            see:
            https://www.science.org/doi/10.1126/sciadv.adh1850

            and:
            https://arxiv.org/ftp/arxiv/papers/2301/2301.11924.pdf
done

TODO, reading "The Internet Is Already Broken"
    see:
    https://wheresyoured.at/p/the-internet-is-already-broken
NA

TODO, reading, Humans Aren’t Mentally Ready for an AI-Saturated ‘Post-Truth World’
    see:
    Humans Aren’t Mentally Ready for an AI-Saturated ‘Post-Truth World’
    https://www.wired.com/story/generative-ai-deepfakes-disinformation-psychology/

    --

    a small article, but contains some pointers to some researchers
done

TODO, reading "Generative agents and artificial societies"
    see:
    https://www.generational.pub/p/generative-agents-and-artificial

NA

TODO, reading "THE DATA TRUST DEFICIT"
    see:
    https://dl.acm.org/doi/pdf/10.1145/3605240

    --

    this work is actually a small associated document related to a main document
    the main document is:

    Why is There a Data Trust Deficit?
    https://www.acm.org/media-center/2023/june/techbrief-data-trust-deficit
done

TODO, reading "Personal Lessons From LLMs"
    see:
    https://matt-rickard.com/personal-lessons-from-llms
done

TODO, reading "30 Signs You Are Living in an Information Crap-pocalypse"
    see:
    https://www.honest-broker.com/p/30-signs-you-are-living-in-an-information
NA

TODO, reading "PoisonGPT: How we hid a lobotomized LLM on Hugging Face to spread fake news"
    today Hacker News dropped an article titled "PoisonGPT: How we hid a lobotomized LLM on Hugging Face to spread fake news"
    this seems to be exactly the thing I was worried about

    but, standard due diligence
    the publisher is "mithril security", do the exist? are they an actual organization?

    then reading
        see:
        https://github.com/pjmattingly/research-repute/tree/main/bib/PoisonGPT%20How%20we%20hid%20a%20lobotomized%20LLM%20on%20Hugging%20Face%20to%20spread%20fake%20news
    done

    then, parsing the Hacker News commentary about the article
        see:
        https://news.ycombinator.com/item?id=36655885
done



----------------



TODO
    TODO, reading list
        links and stories from Hacker News that seem to relate to the topic of repute

        --

        Reddit Won’t Be the Same. Neither Will the Internet
        https://www.wired.com/story/reddit-api-changes-ai-labor/

        --

        How Long Can Open-Source LLMs Truly Promise on Context Length?
        https://lmsys.org/blog/2023-06-29-longchat/

        --

        The Noise Bottleneck: When More Information is Harmful
        https://fs.blog/noise-and-signal-nassim-taleb/

        --

        Sharing Information Corrupts Wisdom of Crowds
        https://archive.ph/FKxaB

    TODO, reading; items sourced from "Prepare for the Textpocalypse"
        see:
        https://github.com/pjmattingly/research-repute/tree/main/bib/Prepare%20for%20the%20Textpocalypse
        
        here we see an early example of the spam problem
        "Exactly that scenario already played out on a small scale when, last June, a tweaked version of GPT-J, an open-source model, was patched into the anonymous message board 4chan and posted 15,000 largely toxic messages in 24 hours."
            see:
            Lessons from the GPT-4Chan Controversy
            https://archive.ph/zKLy0
        
        "William Safire, who was among the first to diagnose the rise of “content” as a unique internet category in the late 1990s, was also perhaps the first to point out that content need bear no relation to truth or accuracy in order to fulfill its basic function, which is simply to exist; or, as Kate Eichhorn has argued in a recent book about content, to circulate."
            see:
            On Language; The Summer Of This Content
            https://archive.ph/HPcGz

        "We face, in essence, a crisis of never-ending spam, a debilitating amalgamation of human and machine authorship. From Finn Brunton’s 2013 book, Spam: A Shadow History of the Internet, we learn about existing methods for spreading spurious content on the internet, such as “bifacing” websites which feature pages that are designed for human readers and others that are optimized for the bot crawlers that populate search engines; email messages composed as a pastiche of famous literary works harvested from online corpora such as Project Gutenberg, the better to sneak past filters (“litspam”); whole networks of blogs populated by autonomous content to drive links and traffic (“splogs”); and “algorithmic journalism,” where automated reporting (on topics such as sports scores, the stock-market ticker, and seismic tremors) is put out over the wires. Brunton also details the origins of the botnets that rose to infamy during the 2016 election cycle in the U.S. and Brexit in the U.K."
            Spam: A Shadow History of the Internet (Infrastructures)
            https://www.amazon.com/dp/026252757X/?tag=theatl0c-20
        
        "Meanwhile, the editor of a long-running science-fiction journal released data that show a dramatic uptick in spammed submissions beginning late last year, coinciding with ChatGPT’s rollout. (Days later he was forced to close submissions altogether because of the deluge of automated content.)"
            see:
            A Concerning Trend
            https://archive.ph/o/tnCyw/neil-clarke.com/a-concerning-trend/

        TODO, check the author and their works
        are they knowledgable on this subject?
        do the listed works (or other related works) seem relevant?
            "Matthew Kirschenbaum is a professor of English and digital studies at the University of Maryland. He is the author of Track Changes: A Literary History of Word Processing (Harvard University Press, 2016) and Bitstreams: The Future of Digital Literary Heritage (University of Pennsylvania Press, 2021)."
    
    TODO, reading, works assocaited with "Decentralized Identity — Owning It!"
        see:
        https://medium.com/coinmonks/decentralized-identity-owning-it-94987f97649f

        --

        Secure Multi-Party Computing (sMPC) — Collaboration Without Sharing
        https://medium.com/coinmonks/secure-multi-party-computing-smpc-collaboration-without-sharing-f92b4a6e3ceb

        --

        What is Blockchain?
        https://medium.com/insatiableminds/what-is-blockchain-8a760d30b802

        --

        zero knowledge proofs, where we may be able to use them to verify evidence of a statement or identity without revealing additional information to an untrusted querier
            Zero Knowledge Proofs: An illustrated primer
            https://blog.cryptographyengineering.com/2014/11/27/zero-knowledge-proofs-illustrated-primer/

            --

            Awesome zero knowledge proofs
            https://github.com/matter-labs/awesome-zero-knowledge-proofs

            --

            Computer Scientist Explains One Concept in 5 Levels of Difficulty | WIRED
            https://www.youtube.com/watch?v=fOGdb1CTu5c

        --

        a real world example of using block chain for identities
            see:

            Inside the Jordan refugee camp that runs on blockchain
            https://www.technologyreview.com/2018/04/12/143410/inside-the-jordan-refugee-camp-that-runs-on-blockchain/

        --

        the W3C definition of a verifiable credential
        which seems helpful for reference, just in case the concept of a verifiable credential turns out to be a good fit for managing individual identity
            see:
            Verifiable Credentials Data Model v1.1
            https://www.w3.org/TR/vc-data-model/#:~:text=A%20verifiable%20credential%20is%20a,can%20be%20about%20different%20subjects

        --

        they also talk about the conept of "revokation" in the article
        where it's sometimes need to "revoke" a credential
        or when updating information
            "This has obvious use cases for professional credentials being revoked for fraud or misconduct, and for driver's licenses being revoked for criminal activity."

            "In addition, it seems likely that the data inside credentials will change over time (e.g., a person's mailing address or phone number updates). This is likely to be quite common, revocation can be used to guarantee currency of credential data when it happens. In other words, revocation may be used to force updated data, not just to revoke authorization."

            --

            0011: Credential Revocation
            https://github.com/hyperledger/indy-hipe/tree/master/text/0011-cred-revocation

    TODO, check the term "game theory of social trust & cooperation"
        as seen in:

        The Evolution of Trust (2017)
        https://news.ycombinator.com/item?id=35807981

        and:
        https://ncase.me/trust/
        https://explorabl.es/social/

        this seems to touch on game theory research into trust, which is closely associated with reputation

        --

        see:
        https://www.google.com/search?q=game+theory+of+social+trust+%26+cooperation&rlz=1C1ONGR_enCA1021CA1021&oq=game+theory+of+social+trust+%26+cooperation&aqs=chrome..69i57j33i10i160.269j0j7&sourceid=chrome&ie=UTF-8
        https://scholar.google.ca/scholar?q=game+theory+of+social+trust+and+cooperation&hl=en&as_sdt=0&as_vis=1&oi=scholart

    TODO, reading; Blockchain Consensus Algorithms
        see:
        https://medium.com/insatiableminds/blockchain-consensus-algorithms-46a9e98c8c07

        --

        this article has a sentence that looks very promising:

        ```
        Byzantine problem highlights the troubles of dealing with a system filled with independent and untrustworthy nodes that need to collaborate together and come up with consensus.

        Sounds familiar? (Cough: Blockchain)
        ```

        this may indicate that my earlier intuitions about Blockchain were well founded
        and Blockchain might be a good basis for tracking repute
        where repute can be thought of as "personal capital"

    TODO, reading; Googling for answers costs you time
        see:
        https://news.ycombinator.com/item?id=36565225
        
        --

        this poster seems to illustrate the process of looking for well-attributed links in Google
        or deciding which content isn't spam
    
    TODO, Anathem started me off thinking about repute, does it have a reference section so I can find out what inspired Stephenson to talk about it?
        see:
        https://en.wikipedia.org/wiki/Anathem

        and:
        https://www.nealstephenson.com/acknowledgments.html
        https://anathem.fandom.com/wiki/Anathem_Wiki

    TODO, go through the existing content and critique; What kind of questions does this raise? What type of research would be helpful to shore up the argument?

    TODO, The pirate community has dealt with this problem, how did they solve it?
        Trust, essentially. They trust some sites, and some people to delivery, because they have shown they are trustworthy over time

    TODO, add notation in README that explains what the different files and section are

    TODO, reading; as drawn from "How to Prepare for the Deluge of Generative AI on Social Media"
        1. J. Haidt and E. Schmidt, AI Is About to Make Social Media (Much) More Toxic. The Atlantic, 2023. https://www.theatlantic.com/technology/archive/2023/05/generative-ai-social-media-integration-dangers-disinformation-addiction/673940/

        3. M. Wong, We Haven’t Seen the Worst of Fake News. The Atlantic, 2022. https://www.theatlantic.com/technology/archive/2022/12/deepfake-synthetic-media-technology-rise-disinformation/672519/

        4. R. DiResta, The Supply of Disinformation Will Soon Be Infinite. The Atlantic, 2020. https://www.theatlantic.com/ideas/archive/2020/09/future-propaganda-will-be-computer-generated/616400/

        7. J.A. Goldstein, et al., Generative Language Models and Automated Influence Operations: Emerging Threats and Potential Mitigations. 2023, arXiv. https://arxiv.org/abs/2301.04246.

        8. R. DiResta, et al., In Bed with Embeds: How a Network Tied to IRA Operations Created Fake “Man on the Street” Content Embedded in News Articles (TAKEDOWN). Stanford Internet Observatory, 2021. https://cyber.fsi.stanford.edu/io/publication/bed-embeds

        9. See A. Narayanan and S. Kapoor, The LLaMA is out of the bag. Should we expect a tidal wave of disinformation?, in AI Snake Oil. 2023. https://aisnakeoil.substack.com/p/the-llama-is-out-of-the-bag-should.

    TODO, reading; as drawn from "AI can spread misinformation better than humans, study claims"    
        Google shares tools to spot misleading AI-generated images
        https://www.siliconrepublic.com/machines/google-ai-generated-images-irish-times-hoax

        Government sets up anti-disinformation working group
        https://www.siliconrepublic.com/business/disinformation-working-group-ireland-media-literacy

        The great AI debate: Moratorium or responsible progress?
        https://www.siliconrepublic.com/machines/the-generative-ai-debate-ethical-moratorium-innovation

    TODO, reading; as drawn from "AI model GPT-3 (dis)informs us better than humans"
        Brown, T. B. et al. Language Models are Few-Shot Learners. (2020) doi:10.48550/arXiv.2005.14165.

        Cabanac, G., Labbé, C. & Magazinov, A. Tortured phrases: A dubious writing style emerging in science.
        Evidence of critical issues affecting established journals. ArXiv210706751 Cs (2021).

        Mindzak, M. & Eaton, S. E. Artificial intelligence is getting better at writing, and universities should
        worry about plagiarism. The Conversation http://theconversation.com/artificial-intelligence-isgetting-better-at-writing-and-universities-should-worry-about-plagiarism-160481 (2021).

    TODO, R&D; as drawn from "Humans Aren’t Mentally Ready for an AI-Saturated ‘Post-Truth World’"
        the article mentioned these researchers, and so it would be helpful to look into their work to see if they are doing any work on AI

        "Larry Rosen" at California State University, Dominguez Hills
        "Michael Graziano" at Princeton
        Michal Kosinski at Standford

    ----

    TODO, take a closer look at NewsGuard
        from: https://support.microsoft.com/en-gb/topic/newsguard-b28e453e-568c-4d57-98ef-c61056f99462
            "NewsGuard is a tool that shows trust ratings for over 7,500 news and information websites."

            ```
            Select the NewsGuard rating to open up a checklist that shows how NewsGuard decided on that website's rating:

            Does not repeatedly post false content

            Gathers and presents information responsibly

            Regularly corrects or clarifies errors

            Handles the difference between news and opinion responsibly

            Avoids deceptive headlines

            Website discloses ownership and financing

            Clearly labels advertising

            Reveals who’s in charge, including any possible conflicts of interest

            Provides information about content creators
            ```

        and, from: https://en.wikipedia.org/wiki/NewsGuard
            ```
            NewsGuard is a journalism and technology tool that rates the credibility of news and information websites and tracks online misinformation. It operates a browser extension and mobile apps for consumers as well as services for businesses, including a brand safety tool for advertisers[2] and services for search engines, social media apps, cybersecurity firms, and government agencies.[3]
            ```

        this seems to be an organization that is concerned about repute, just as I am
        what does their tool do? what is it like when used?
    
    ----

    TODO, reading, AI Is Making Politics Easier, Cheaper and More Dangerous
        see:
        https://archive.ph/0MKma#selection-3795.0-3795.56
        https://www.bloomberg.com/news/features/2023-07-11/chatgpt-ai-boom-makes-political-dirty-tricks-easier-and-cheaper#xj4y7vzkg

    TODO, reading, 5 Ways Decentralized Identity Will Impact the Internet and Our Privacy
        see:
        https://www.makeuseof.com/ways-decentralized-identity-will-impact-internet/

    TODO, reading, ChatGPT Already Floods Some Corners of the Internet With Spam. It’s Just the Beginning.
        see:
        https://archive.ph/7fGAf
        https://www.wsj.com/articles/chatgpt-already-floods-some-corners-of-the-internet-with-spam-its-just-the-beginning-9c86ea25

    TODO, reading, GPT might be an information virus
        see:
        https://nonint.com/2023/03/09/gpt-might-be-an-information-virus/
        https://news.ycombinator.com/item?id=36675335

        --

        also, the top comment talks about trust:
            ```
            The issue is trying to look for technical solutions to what is fundamentally a social problem. That problem is trust.
            Over the previous few decades, the web has slid from a place that felt like a small village to a bustling metropolis. In a large city, trust is maintained first via politeness norms suited to anonymised societies (like civil inattention) — we trust that others will leave us alone — and second (and perhaps more prominently) by explicit institutions (emergency services, businesses, media).

            Similarly, trust in information on the Internet has been mediated by implicit rules (consider how many people will add "Reddit" at the end of their Google search) and explicit institutions (such as search engines and social media platforms).

            Though I agree with a lot of the article's conclusions, I feel that it falls into the same trap that a lot of tech commentators do. Ultimately, though I'm certainly worried (like most of us) about the ramifications of AI, including as the article mentions how we'll navigate a noise-saturated information environment, I think we will find a way. No technology will alter the fact that humans will always seek out trust*.
            ```
                see:
                https://news.ycombinator.com/item?id=36678466

    ----

    TODO, reading "Junk websites filled with AI-generated text are pulling in money from programmatic ads"
        see:
        https://www.technologyreview.com/2023/06/26/1075504/junk-websites-filled-with-ai-generated-text-are-pulling-in-money-from-programmatic-ads/

        --

        the article is a summary of another article
            see:
            Funding the Next Generation of Content Farms:
            Some of the World’s Largest Blue Chip Brands Unintentionally Support the Spread of Unreliable AI-Generated News Websites
            https://www.newsguardtech.com/misinformation-monitor/june-2023/

        and so including both in the same bib item
            see:
            https://github.com/pjmattingly/research-repute/tree/main/bib/Junk%20websites%20filled%20with%20AI-generated%20text%20are%20pulling%20in%20money%20from%20programmatic%20ads

        next,

        reading
        Junk websites filled with AI-generated text are pulling in money from programmatic ads

    TODO, reading, "Gödel, Escher, Bach, and AI"
        see:
        https://www.theatlantic.com/ideas/archive/2023/07/godel-escher-bach-geb-ai/674589/
    


----------------

IDEAs
    idea, this is a spam problem, so what's the history of spam?

    idea, I think the issue might be that cost of producing high quality spam has lowered significantly, while at the same time the difficulty of detecting the spam has risen significantly
        so much so that it almost takes an expert to tell the difference between a real document and a spam one

    idea, rather than binary trust, trust should be real-valued
        that is, we're pretty sure we can trust an agent, but we can never be 100% certain
        and there may be value in documents from those with lower repute
        though their content should be held under suspicion
        that is, guilty until proven innocent

    idea, what about game theory?
        is there a theory of trust that is modeled by game theory?

    idea, this is a magnification of the spam problem
        Or: How do you find signal (human authored information whose information is useful to some party)
        in the noise (spam, propaganda, bad actors, advertising, etc)

    idea, is this a tragedy of the commons?
        Those that see profit in the shared space of the Internet, have every reason to exploit it and little reason to preserve it
        While those that seek to exchange information and make connection do have reason to preserve it

    idea, why not make a rough copy of an existing site and use that for serving ads or some other purpose
        as seen in
            Funding the Next Generation of Content Farms:
            Some of the World’s Largest Blue Chip Brands Unintentionally Support the Spread of Unreliable AI-Generated News Websites
            https://www.newsguardtech.com/misinformation-monitor/june-2023/

        they note sites that make money by serving low effort content or plagarised content
        the authors were able to catch the sites, because they were low quality and had content that was easily detected as low effort or plagarized
        
        but what about copying a real site, and then just paraphrasing the articles as they come out

        this way it becomes difficult to detect that the fake sites is fake
        since its release cadence mimics that of the real site
        and its content is just plagarised from the real site
        so the article seem real, the authors can seem real, the release cadence can seem real, the layout can seem real as it is real (lifted from the host site)

        that should make such sites almost impossible to detect
        then with slight alterations to the site's appearance, it can be just different enough to make detection of it as an exact duplicate very difficult to detect

        I wonder if an LLM could "rephrase" the site code as well as the content?

----------------

note, for articles that are especially helpful, check for Hacker News threads for them
    there may be useful discourse, references, or links to use